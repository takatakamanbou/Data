{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP11Y1gLOg8WKd604SZvexJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/Data/blob/2023/ex09notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# Data2023 ex09notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/Data-logo09.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2023\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4-TmUdCd9FJ"
      },
      "source": [
        "## 準備\n",
        "\n",
        "\n",
        "以下，コードセルを上から順に実行していってね．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8M3640S1W7"
      },
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If5pCB6bc3QF"
      },
      "source": [
        "# データを読み込む  ゴリゴリくん\n",
        "dfGori = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/ex08gorigori.csv', header=0)\n",
        "#dfGori"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ozwh3xYIZJQ"
      },
      "source": [
        "# データを読み込む  数学物理情報\n",
        "dfMPI = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/ex06mpi.csv', header=0)\n",
        "#dfMPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyAzAhxsaxPD"
      },
      "source": [
        "# データを読み込む  Anscombe's quartet\n",
        "dfAnscombe = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/ex10Anscombe.csv', header=0)\n",
        "#dfAnscombe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H45eNIcd2xB"
      },
      "source": [
        "----\n",
        "## 回帰分析入門(4)  \n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4RlkyhP5yo"
      },
      "source": [
        "----\n",
        "### 決定係数とは\n",
        "\n",
        "回帰分析の実習課題で登場した **決定係数** について説明します．\n",
        "この値は，回帰直線がどれくらいデータに当てはまっているかを表し，回帰分析の結果の良し悪しを判断するのに用いることができます．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCHvtTlCUwNe"
      },
      "source": [
        "いつものように\n",
        "\n",
        "$$\n",
        "(x_n, y_n)\\quad (n = 1, 2, \\dots , N)\n",
        "$$\n",
        "\n",
        "という $N$ 組のデータを考え，文字 $x$ で表された方を説明変数（独立変数）， $y$ で表された方を被説明変数（従属変数，目的変数）とします．\n",
        "\n",
        "**決定係数** は，「被説明変数$y$の変動のうちどれくらいを説明変数によって説明できているか」を表す値です． 多くの場合，$r^2$ または $R^2$ という記号で表され，次のように定義されます．\n",
        "\n",
        "$$\n",
        "r^2 = 1 - \\frac{\\displaystyle\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2}{\\displaystyle\\sum_{n=1}^{N}(y_n - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "ただし，$\\hat{y}_n$ や $\\bar{y}$ は，これまでと同様です．$\\hat{y}_n$ は，$x_n$ に対応する予測値，$\\bar{y}$ は $y$ の平均です．\n",
        "\n",
        "分子の式\n",
        "\n",
        "$$\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2$$\n",
        "\n",
        "は，「回帰直線による予測残差の平方和」です．\n",
        "回帰直線で $x$ から $y$ を予測してみたが予測しきれず残った値の散らばり，を表します．\n",
        "一方，分母の式\n",
        "\n",
        "$$\\sum_{n=1}^{N}(y_n - \\bar{y})^2$$\n",
        "\n",
        "は，$y$ の分散を $N$ 倍したものになっており，「被説明変数$y$の変動の大きさ」，つまり，もともと $y$ の値がどれくらい散らばっていたか，を表します．つまり，\n",
        "\n",
        "$$\n",
        "r^2 = 1 - \\frac{\\mbox{予測しきれず残った値の散らばりの大きさ}}{\\mbox{もともとの$y$の散らばりの大きさ}}\n",
        "$$\n",
        "\n",
        "ということです．\n",
        "\n",
        "説明変数 $x$ から被説明変数 $y$ が完全に予測できた場合は，残差平方和が $0$ になりますので，$r^2 = 1$ となります．\n",
        "一方，直線当てはめによる予測が全くうまくいかない場合は，もともとの $y$ の散らばりが全部残ったままで分子の残差平方和が分母の値と等しくなるので，$r^2 = 0$ となります．\n",
        "したがって，直線を当てはめる回帰分析においては，$0 \\leq r^2 \\leq 1$ であり，$r^2$ の値は $1$ に近いほど当てはまりがよい，ということになります．\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuNBo1wOhRpk"
      },
      "source": [
        "実際のデータで確認してみましょう．まずは，「ゴリゴリくん」．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG77JC04ffkh"
      },
      "source": [
        "# データ\n",
        "X = dfGori['気温'].to_numpy()\n",
        "Y = dfGori['アイス売上数'].to_numpy()\n",
        "xmin, xmax = -5, 40\n",
        "ymin, ymax = 0, 130\n",
        "\n",
        "# 最小二乗法による直線のあてはめ\n",
        "a, b = np.polyfit(X, Y, 1)\n",
        "Yest = a * X + b\n",
        "\n",
        "# ST: Y の変動   E: 予測残差平方和  R2: 決定係数\n",
        "ST = np.var(Y) * len(Y)\n",
        "E = np.sum((Yest - Y)**2)\n",
        "R2 = 1 - E/ST\n",
        "print(f'Yの変動: {ST:.1f}  予測残差平方和: {E:.1f}   決定係数: {R2:.3f}')\n",
        "\n",
        "# グラフを描く\n",
        "Xr = np.array([xmin, xmax])\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(9, 6))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, a*Xr + b, color='red')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(ymin, ymax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqEYIRsxh8NP"
      },
      "source": [
        "次は，「数学」vs「情報」．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rldGU2HMh7S5"
      },
      "source": [
        "# データ\n",
        "X = dfMPI['数学'].to_numpy()\n",
        "Y = dfMPI['情報'].to_numpy()\n",
        "xmin, xmax = 0, 100\n",
        "ymin, ymax = 0, 100\n",
        "\n",
        "# 最小二乗法による直線のあてはめ\n",
        "a, b = np.polyfit(X, Y, 1)\n",
        "Yest = a * X + b\n",
        "\n",
        "# ST: Y の変動   E: 予測残差平方和  R2: 決定係数\n",
        "ST = np.var(Y) * len(Y)\n",
        "E = np.sum((Yest - Y)**2)\n",
        "R2 = 1 - E/ST\n",
        "print(f'Yの変動: {ST:.1f}  予測残差平方和: {E:.1f}   決定係数: {R2:.3f}')\n",
        "\n",
        "# グラフを描く\n",
        "Xr = np.array([xmin, xmax])\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(6, 6))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, a*Xr + b, color='red')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(ymin, ymax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q884pE4Llc_q"
      },
      "source": [
        "決定係数を見ると，「ゴリゴリくん」方は $1$ に近いのに対して，「数学vs情報」の方はずっと小さくなっています．\n",
        "散布図に回帰直線を重ねたグラフの方を見ても，実際，「ゴリゴリくん」はそれなりに当てはまっているように見えますが，「数学vs情報」の方はあまり当てはまりが良くなく，残差が大きそうですね．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwuKqM98mlOa"
      },
      "source": [
        "決定係数の成り立ちと意味を直感的に理解するため，上記のデータを利用して作った図を載せておきます．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/ex11-residual.png\">\n",
        "\n",
        "左の図の青い水平線は，「ゴリゴリくん」の被説明変数 $y$ の平均 $\\bar{y}$ です．上下に伸びた青い矢印は，いくつかの値 $y_n$ の偏差（平均からのずれ） $y_n - \\bar{y}$ を表します．\n",
        "これらの二乗和が，「もともとの $y$ の散らばり」 $\\sum_{n=1}^{N}(y_n - \\bar{y})^2$ です．\n",
        "\n",
        "一方，右の図の赤い直線は回帰直線を表し，上下に伸びた赤い矢印は，いくつかの値の予測残差 $y_n - \\hat{y}_n$ を表します．\n",
        "これらの二乗和が，「予測残差平方和」 $\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2$ です．\n",
        "\n",
        "「もともとの $y$ の散らばり」に比べて「予測残差平方和」 の値はかなり小さくなっていますね．そのため，決定係数の値は大きく（$1$に近く）なっています．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAzV0E4EoqBd"
      },
      "source": [
        "「数学vs情報」でも同様の図を描いてみると，こんなんです．\n",
        "「予測残差平方和」が「もともとの $y$ の散らばり」に比べてあまり小さくなっておらず，そのため決定係数の値が小さいことが見てとれます．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/ex11-residual2.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jSlG3sCpVNf"
      },
      "source": [
        "### 決定係数と相関係数の関係\n",
        "\n",
        "2つの変数の間の関係を表す量として，以前，**相関係数** というものを説明しました（参考: [Data2023第5回](https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2023#ex05)）\n",
        "直線を当てはめる回帰分析の決定係数は，この相関係数と結びついています．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puKKR05uxmNE"
      },
      "source": [
        "**相関係数**（復習）\n",
        "\n",
        "$$\n",
        "(x_n, y_n)\\quad (n = 1, 2, \\dots , N)\n",
        "$$\n",
        "\n",
        "という $N$ 組のデータが与えられたとき，このデータの相関係数 $r$ は次式で定義されます．\n",
        "\n",
        "$$\n",
        "r =  \\frac{s_{xy}}{s_x s_y} = \\frac{\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}(x_n - \\bar{x})(y_n - \\bar{y})}{\\displaystyle\\sqrt{\\frac{1}{N}\\sum_{n=1}^{N}(x_n - \\bar{x})^2}\\sqrt{\\frac{1}{N}\\sum_{n=1}^{N}(y_n - \\bar{y})^2}}\n",
        "$$\n",
        "\n",
        "$r$ は $-1 \\leq r \\leq 1$ を満たします．\n",
        "\n",
        "ここで，\n",
        "\n",
        "$$\n",
        "s_x = \\sqrt{\\frac{1}{N}\\sum_{n=1}^{N}(x_n - \\bar{x})^2}\\qquad\n",
        "s_y= \\sqrt{\\frac{1}{N}\\sum_{n=1}^{N}(y_n - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "はそれぞれ $x$ と $y$ の標準偏差です（$\\bar{x}, \\bar{y}$は $x, y$ それぞれの平均）．\n",
        "また，\n",
        "\n",
        "$$\n",
        "s_{xy} = \\frac{1}{N}\\sum_{n=1}^{N}(x_n - \\bar{x})(y_n - \\bar{y})\n",
        "$$\n",
        "\n",
        "は，$x$ と $y$ の共分散です．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srpmbbtXzfWZ"
      },
      "source": [
        "「相関係数と決定係数に同じ記号 $r$ 使っててややこしいぞ」と思うかもなところですが，実は，直線当てはめの回帰分析における決定係数と相関係数との間には，「**決定係数は相関係数の2乗に等しい**」という関係が成り立ちます（証明は省略します）．\n",
        "つまり，これまでの決定係数の説明に登場していた　$r^2$ という式の $r$ は，相関係数そのものだった，というわけです．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCGXnbu72OuK"
      },
      "source": [
        "以下のセルを実行すると，「ゴリゴリくん」と「数学vs情報」の相関係数とその2乗の値が出力されます．\n",
        "上の決定係数の値と見比べてみてください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7jqwrf1e-d"
      },
      "source": [
        "# 「ゴリゴリくん」\n",
        "X = dfGori['気温'].to_numpy()\n",
        "Y = dfGori['アイス売上数'].to_numpy()\n",
        "r = np.corrcoef(X, Y)[0][1]\n",
        "print(f'相関係数: {r:.3f}  その2乗: {r*r:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxEeeg0A2HiP"
      },
      "source": [
        "# 「数学vs情報」\n",
        "X = dfMPI['数学'].to_numpy()\n",
        "Y = dfMPI['情報'].to_numpy()\n",
        "r = np.corrcoef(X, Y)[0][1]\n",
        "print(f'相関係数: {r:.3f}  その2乗: {r*r:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8SMSVYF2fKa"
      },
      "source": [
        "決定係数の値が相関係数の2乗に等しいということは，「データから相関係数を求めれば，そのデータに直線を当てはめる回帰分析を行ったときに，どのくらい当てはまりがよいかがわかる」ということを意味します．\n",
        "相関係数の絶対値が大きい，つまり $1$ または $-1$ に近いときは，決定係数は $1$ に近い値となり，直線がよくあてはまります．\n",
        "一方，相関係数が $0$ に近いときは，決定係数も $0$ に近く，直線があまりよくあてはまりません．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dogmFuo-dtOJ"
      },
      "source": [
        "----\n",
        "### データ分析における注意点\n",
        "\n",
        "以下は，以前の「回帰分析の注意点」という話の一部と同じような内容ですが，大事なことなので繰り返しておきます．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QPypYJf8VnZ"
      },
      "source": [
        "こんなデータがあります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fUl8l_y59tv"
      },
      "source": [
        "dfAnscombe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3yo4XhQ8YgK"
      },
      "source": [
        "x1とy1，x2とy2，x3とy3，x4とy4のそれぞれでペアを作った4通りのデータについて，平均や分散などの代表値を求めてみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-QbEygx9Hqm"
      },
      "source": [
        "for i in range(1, 5):\n",
        "    print(f'(x{i}, y{i})', end='  ')\n",
        "    X = dfAnscombe[f'x{i}']\n",
        "    Y = dfAnscombe[f'y{i}']\n",
        "    print(f'x の平均: {np.mean(X):.3f}  x の分散: {np.var(X):.3f}', end='  ')\n",
        "    print(f'y の平均: {np.mean(Y):.3f}  y の分散: {np.var(Y):.3f}', end='  ')\n",
        "    print(f'相関係数: {np.corrcoef(X, Y)[0][1]:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drae0cAL86yA"
      },
      "source": [
        "これら4通りのデータは，平均，分散や相関係数がほぼ等しい値となっています．\n",
        "ならば，散布図を描いたら，同じような見た目になるでしょうか？ 回帰分析したらどうなるでしょうか？\n",
        "\n",
        "こんなんなります．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yhDXVmK6MXK"
      },
      "source": [
        "xmin, xmax = 0, 20\n",
        "ymin, ymax = 0, 15\n",
        "fig, ax = plt.subplots(2, 2, facecolor='white', figsize=(9, 6))\n",
        "for i in range(4):\n",
        "    j, k = i // 2, i % 2\n",
        "    X = dfAnscombe[f'x{i+1}']\n",
        "    Y = dfAnscombe[f'y{i+1}']\n",
        "    a, b = np.polyfit(X, Y, 1)\n",
        "    Xr = np.array([xmin, xmax])\n",
        "    ax[j, k].scatter(X, Y)\n",
        "    ax[j, k].plot(Xr, a*Xr + b, color='red')\n",
        "    ax[j, k].set_xlim(xmin, xmax)\n",
        "    ax[j, k].set_ylim(ymin, ymax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mw_k6DBFns"
      },
      "source": [
        "見ての通り，これらはデータの散らばり方が全く異なっています．\n",
        "平均や分散などの代表値だけを見てデータの分布を想像することは危険だよ，散布図を描くなど可視化することが大事だよ，ということです．\n",
        "\n",
        "また，回帰直線については，最初の1つはまともですが，2番目は2つの変数間の関係が直線でないため，うまく当てはまってません．\n",
        "3番目と4番目は，外れ値の影響で，おかしな結果となっています．\n",
        "これらの結果もまた，可視化の重要性，外れ値などの影響に注意することの重要性を示しています．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRQj6fvCDOb3"
      },
      "source": [
        "上記の例は， 「Anscombe's quartet（アンスコムの例）」という名前で，データ分析／統計の分野でよく知られたものです．\n",
        "参考: [Wikipedia アンスコムの例](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%82%B9%E3%82%B3%E3%83%A0%E3%81%AE%E4%BE%8B)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzASFL_9DM4J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}